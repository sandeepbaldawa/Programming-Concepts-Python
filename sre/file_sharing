http://blog.marc-seeger.de/2008/07/23/the-current-state-of-anonymous-file-sharing/
http://krondo.com/in-which-we-begin-at-the-beginning/

questions:-
==========
machines:- sizing, heterogenous, IOPs, queueing, 

server:- async, sync?, vertical scaling to handle threads synchronously? or have asynch threading model

Network:- bandwidth?


Compared to the synchronous model, the asynchronous model performs best when
=============================================================================
1. There are a large number of tasks so there is likely always at least one task that can make progress.
2. The tasks perform lots of I/O, causing a synchronous program to waste lots of time blocking when other tasks could be running.
3. The tasks are largely independent from one another so there is little need for inter-task communication 
(and thus for one task to wait upon another).
4. The I/O part of threaded code is relatively easy but managing the shared state between threads (using locks/queues/etc)
   without race conditions is what makes it tricky. Using an async model means you have less going on at the same time so races are easily avoided. 2/3.
   each thread will consume at least one memory page of stack (4KB or 8KB typically), plus some unknown amount of memory for 
   other data structures related to that thread's state.
5. It is very difficult to write code that is thread safe. 
   With asyncronous code you know exactly
   where the code will shift from one task to the next and race conditions are much therefore much harder to come by. Threads
   consume a fair amount of data since each thread needs to have its own stack;
   with async code all the code shares the same stack and the stack is kept small due to continuously unwinding the stack between tasks. Threads are OS structures
   and are therefore more memory for the platform to support. There is no such problem with asynchronous tasks.


A distributed system is an application that executes a collection of protocols to coordinate the
actions of multiple processes on a network, such that all components cooperate together to perform
a single or small set of related tasks.

To be truly reliable, a distributed system must have the following characteristics:
1. Fault-Tolerant: It can recover from component failures without performing incorrect actions.
2. Highly Available: It can restore operations, permitting it to resume providing services even when some components have failed.
3. Recoverable: Failed components can restart themselves and rejoin the system, after the cause of failure has been repaired.
4. Consistent: The system can coordinate actions by multiple components often in the presence of concurrency and failure.
   This underlies the ability of a distributed system to act like a non-distributed system.
5. Scalable: It can operate correctly even as some aspect of the system is scaled to a larger size. For example, we might increase the size of the network on which the system is running. This increases the frequency of network outages and could degrade a "non-scalable" system. Similarly, we might increase the number of users or servers, or overall load on the system. In a scalable system, this should not have a significant effect.
6. Predictable Performance: The ability to provide desired responsiveness in a timely manner.
7. Secure: The system authenticates access to data and services

Handling failures is an important theme in distributed systems design. Failures fall into two obvious categories: 
hardware and software. Today, problems are most often associated with connections and mechanical devices, 
i.e., network failures, node failures and drive failures.


