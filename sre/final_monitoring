Goals
====
- Good interface, with minimum clicking to get to good data.
- Qualitative measurement of metrics with deterministic outcome.
- Collect network, application and performance from remote sites and analyze
- visualizing operational metrics of various services
- easily configurables metrics(publisher/subscriber)
- calibrating metrics to proper intervals to avoid itter introduced by time-boxing smaller intervals
- Alerting to predict patterns of behavior
- Automation for most tasks like collecting, adding, analyzing a metric.
- Abilty to co-relate different metrics without much user intervention
- Reduce noise by giving capability to serives/users to listen to only what one is interested in
- Easy to add new people and keep up with the growth of new engineers.
- Not much touch points to add a metric. Metrics adding should be automated and error free
- Consistent set of metrics to work with
- Optimum performance(eg:- time it takes for queries) and space usage.

- automated monitoring important because of the sheer scale of services to monitor. Also to reduce noise
  Publisher subscriber would be better applicable. Automated reporting too is equally important.
- Subscribers can be microservices which inrepret this data.  
- Generating graphs/pictures important for understanding behavior/anamolies etc mainly because of the sheer amount of data
  present, it will be very difficult to understand the same manually. 
- Policies and response rules to judge the system

Design
=======
1. Graphing tools provide a clear and nearly-immediate signal that something is broken (and badly). 
We can use this signal to trigger alerts and escalate to someone to take a look. So it's important we
have few entities

Data collection from various sources
  A script running on each host discovers the services running, parses the GC log for that service, and pumps out 
  metrics. 
  Granularity is very important as it allows one to zoom in to collect more details.
  Ability to collect different metrics and from heterogenous sources
  eg:-
  Accessibility of intranet and internet sites
  Collecting metrics like packet loss, latency, jitter between all sites and datacenters with QOS Queues
  Intranet and internet link failover check
  Accessibility of cloud services
  Accessibility of critical corporate applications
  Speed / throughput of network (intranet/internet)

Modules generating graphs from these sources
Services have flexibility to subscribe to which graph to monitor specific characteristics
Policy manager to decide when to generate alerts


Collecting metrics
=================
- Each Service can generate metrics.
- Collect the standard cross-service metrics automatically from every service
- broker which can publish these services and interested parties can subscribe to the same.
- resolution of metrics(intervals they are served) important.
- capacity planning for infrastructure important, since amount of data is huge
   understand WCU, RCU, IOPs, throughput, latency, 
- Configuring(adding/removing) metrics should be easy at various levels, GUI, command line, code etc.
- Programatically name the metrics so we can do things based on the format
- A push based system(forcasting what might be needed) that always sent the metrics it had regardless of being
  in a data store or not

Graphing frontend
================

- RRDtool is the OpenSource industry standard, high performance data logging and graphing system 
for time series data. RRDtool can be easily integrated in shell scripts, perl, python, ruby, lua or tcl applications.
- 



  
