https://www.scalyr.com/community/guides/zen-and-the-art-of-system-monitoring
https://landing.google.com/sre/book/chapters/monitoring-distributed-systems.html

Why Monitor?
============

There are many reasons to monitor a system, including:

1. Analyzing long-term trends
How big is my database and how fast is it growing? How quickly is my daily-active user count growing?

2. Comparing over time or experiment groups
Are queries faster with Acme Bucket of Bytes 2.72 versus Ajax DB 3.14? How much better is my memcache hit rate with an extra node? Is my site slower than it was last week?

3. Alerting
Something is broken, and somebody needs to fix it right now! Or, something might break soon, so somebody should look soon.

4. Building dashboards
Dashboards should answer basic questions about your service, and normally include some form of the four golden signals (discussed later in this chapter).

5. Conducting adhoc retrospective analysis (i.e., debugging)
Our latency just shot up; what else happened around the same time?

6. System monitoring is also helpful in supplying raw input into business analytics 

7. Facilitating analysis of security breaches

Lots of white-box monitoring
Some black-box monitoring for critical stuff
Four golden signals
Latency
Traffic
Errors
Saturation

Black-box monitoring
====================
Testing externally visible behavior as a user would see it.

White-box monitoring
====================
Monitoring based on metrics exposed by the internals of the system, including logs,
interfaces like the Java Virtual Machine Profiling Interface, or an HTTP handler that emits internal statistics.

Dashboard
=========
An application (usually web-based) that provides a summary view of a service’s core metrics. 
A dashboard may have filters, selectors, and so on, but is prebuilt to expose the metrics most important to its users.

Root cause
==========
A defect in a software or human system that, if repaired, instills confidence that this event won’t happen again in the same way. A given incident might have multiple root causes: for example, perhaps it was caused by a combination of insufficient process automation, software that crashed on bogus input, and insufficient testing of the script used to generate the configuration. Each of these factors might stand alone as a root cause, and each should be repaired.


Alert
======
A notification intended to be read by a human and that is pushed to a system such as a bug or ticket queue, 
an email alias, or a pager. Respectively, these alerts are classified as tickets, email alerts,1 and pages.
The dashboard might also display team information such as ticket queue length, a list of high-priority bugs, 
the current on-call engineer for a given area of responsibility, or recent pushes.

Outages can be prolonged because
other noise interferes with a rapid diagnosis and fix. Effective alerting systems have good signal and very low noise.
When pages occur too frequently, employees second-guess, skim, or even ignore incoming alerts, 
sometimes even ignoring a "real" page that’s masked by the noise.
Very important to balance between right amount of alerting, info, warning etc. types of messages to avoid too much information
which is difficult to traige.

Node and machine
================
Used interchangeably to indicate a single instance of a running kernel in either a physical server, virtual machine, or container. There might be multiple services worth monitoring on a single machine. The services may either be:

Related to each other: for example, a caching server and a web server
Unrelated services sharing hardware: for example, a code repository and a master for a configuration system like Puppet or Chef

Push
Any change to a service’s running software or its configuration.

capacity planning and traffic prediction
========================================
Base on disk filing up or cluster filing up or based on the runnign traffic..

Policies and response rules
===========================

Minotiring capacity and plan capacity
Monitor failure rate of devices, nodes, h/w etc..and predict when we would need a new device and alert user..
try to make alerting as specific as possible eg:- db is slow instead of website is slow..
asup emails..

Understanding symtoms vs cause
===============================
our monitoring system should address two questions: what’s broken, and why?

The "what’s broken" indicates the symptom; the "why" indicates a (possibly intermediate) cause


Symtoms => Cause
I’m serving HTTP 500s or 404s => Database servers are refusing connections 
My responses are slow => CPUs are overloaded by a bogosort, or an Ethernet cable is crimped under a rack,
                         visible as partial packet loss
Users in Antarctica aren’t receiving animated cat GIFs => Your Content Distribution Network hates scientists and felines, 
                                                          and thus blacklisted some client IPs
Private content is world-readable => A new software push caused ACLs to be forgotten and allowed all requests
